{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Language Modelling Sequence Model\n",
    "Made as a part of the Deep Learning project \"19 State-of-the-Art Language Modelling\" (fall 2020) at DTU. \n",
    "\n",
    "Authors:\n",
    "Lucas Alexander Sørensen,\n",
    "Marc Sun Bøg &\n",
    "Simon Amtoft Pedersen"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader\n",
    "from tokenizers import Tokenizer\n",
    "from datasets import load_from_disk\n",
    "\n",
    "from SeqModel import Seq\n",
    "from TrainHelpers import *\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(DEVICE)\n",
    "print('Using device \"{}\"'.format(device))\n",
    "\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained tokenizer\n",
    "tokenizer = Tokenizer.from_file(config.PATH_TOKENIZER)\n",
    "\n",
    "if config.VOCAB_SIZE != tokenizer.get_vocab_size():\n",
    "    print(\n",
    "        'Retrain Tokenizer. Vocab size {} != {}'\n",
    "        .format(config.VOCAB_SIZE, tokenizer.get_vocab_size())\n",
    "    )"
   ]
  },
  {
   "source": [
    "# Setup Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(train_ds, val_ds, test_ds) = (\n",
    "    load_from_disk(config.PATH_TRAIN_TOK), \n",
    "    load_from_disk(config.PATH_VAL_TOK), \n",
    "    load_from_disk(config.PATH_TEST_TOK)\n",
    ")\n",
    "\n",
    "train_ds.set_format(type=\"pt\", columns=[\"ids\", \"n\"])\n",
    "val_ds.set_format(type=\"pt\", columns=[\"ids\", \"n\"])\n",
    "test_ds.set_format(type=\"pt\", columns=[\"ids\", \"n\"])\n",
    "\n",
    "# Concatenate tensors to one long sequence.\n",
    "train_ids = torch.cat(train_ds[\"ids\"])\n",
    "val_ids   = torch.cat(val_ds[\"ids\"])\n",
    "test_ids  = torch.cat(test_ds[\"ids\"])\n",
    "\n",
    "train_n = train_ds[\"n\"]\n",
    "val_n   = val_ds[\"n\"]\n",
    "test_n  = test_ds[\"n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = prep_batches(train_ids, config.BATCH_SIZE, config.SEQ_LEN, print_every=1000)\n",
    "val_batches = prep_batches(val_ids, config.BATCH_SIZE, config.SEQ_LEN)\n",
    "test_batches = prep_batches(test_ids, config.BATCH_SIZE, config.SEQ_LEN)"
   ]
  },
  {
   "source": [
    "# Train Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sequence(init=\"\", max_len=config.SEQ_LEN, tau=1, device=device):\n",
    "    with torch.no_grad():\n",
    "        CLS = tokenizer.token_to_id(\"[CLS]\")\n",
    "        EOS = tokenizer.token_to_id(\"[EOS]\")\n",
    "\n",
    "        h = torch.zeros((N_LAYERS, 1, HIDDEN_DIM)).to(device)\n",
    "        c = torch.zeros_like(h).to(device)\n",
    "        x = torch.tensor(tokenizer.encode(init).ids).long().to(device)\n",
    "        # find EOS \n",
    "        l = torch.where(x == EOS)[0]\n",
    "        x = x[:l]\n",
    "\n",
    "        tokens = x.detach().clone().tolist()\n",
    "\n",
    "        for i in range(0, max_len):\n",
    "            # reshape to (1, seq_len)\n",
    "            x = x.view(1, -1)\n",
    "            lgts, h, c = model(x, h, c)\n",
    "            probs = nn.functional.softmax(lgts[-1]/tau, dim=1)\n",
    "            cat = torch.distributions.categorical.Categorical(probs=probs[-1])\n",
    "            x = cat.sample()\n",
    "            tokens.append(x.item())\n",
    "            if x == EOS:\n",
    "                break\n",
    "        return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters used in training loop\n",
    "HIDDEN_DIM = config.PARAM['hidden_dim']\n",
    "N_LAYERS = config.PARAM['n_layers']\n",
    "\n",
    "# Define training parameters\n",
    "LEARNING_RATE = 0.7     # pretty big learning rate. Same one was used in Seq2Seq.\n",
    "WEIGTH_DECAY = 0\n",
    "MOMENTUM = 0\n",
    "EPOCHS = 5\n",
    "NUM_BATCHES = len(train_batches[0])\n",
    "GRADIENT_CLIP = 5\n",
    "STEP_SIZE = 1        # multiply lr by GAMMA every STEP_SIZE epochs.\n",
    "GAMMA = 0.85            # Reduce learning rate by 25% pr. step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Seq(config.VOCAB_SIZE, config.PARAM, device, weight_tying = False)\n",
    "if config.LOAD_PRETRAINED:\n",
    "    model.load_state_dict(torch.load(config.PATH_MODEL))\n",
    "    \n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=LEARNING_RATE, \n",
    "    momentum=MOMENTUM, \n",
    "    weight_decay=WEIGTH_DECAY\n",
    ")\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, STEP_SIZE, gamma=GAMMA, last_epoch=-1, verbose=False)\n",
    "\n",
    "print(sum([np.prod(p.size()) for p in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "model.to(device)\n",
    "import time\n",
    "start_time = time.time()\n",
    "for e in range(EPOCHS):\n",
    "    h = torch.zeros((N_LAYERS, config.BATCH_SIZE, HIDDEN_DIM)).to(device)\n",
    "    c = torch.zeros_like(h).to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for i in range(0, NUM_BATCHES):\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        h.detach_()\n",
    "        c.detach_()\n",
    "\n",
    "        # Get input and target\n",
    "        inputs = train_batches[0][i].to(device)\n",
    "        targets = train_batches[1][i].to(device)\n",
    "\n",
    "        # Predict with model\n",
    "        lgts, h, c = model(inputs, h, c)  # Logits: [batch, vocab_size, seq_len]\n",
    "        lgts = lgts.transpose(1, 2)       # [batch, vocab size, seq len]\n",
    "        loss = criterion(lgts, targets)   # Targets: [batch, seq_len]\n",
    "\n",
    "        # get loss and optimize\n",
    "        loss_val = loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save models each config.PRINT_LOSS_EVERY_N_BATCH iteration\n",
    "        if i % config.PRINT_LOSS_EVERY_N_BATCH == 0:\n",
    "            # torch.save(model.state_dict(), config.PATH_MODEL) \n",
    "            print(\n",
    "                'Epoch: {}/{}\\tIteration: {}/{} \\tLoss: {}\\t Learning Rate: {}\\tTraining duration: {}'\n",
    "                .format(e+1, EPOCHS, i+1, NUM_BATCHES, loss_val, scheduler.get_last_lr(), time.time() - start_time)\n",
    "            )\n",
    "            print(\"=== Randomly sampled string ===\")\n",
    "            model.eval()\n",
    "            print(tokenizer.decode(sample_sequence(max_len=32, tau=0.1)))\n",
    "            model.train()\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    sum_loss = 0\n",
    "    for i in range(0, len(val_batches[0])):\n",
    "      _h = torch.zeros_like(h)\n",
    "      _c = torch.zeros_like(c)\n",
    "      inputs = val_batches[0][i].to(device)\n",
    "      targets = val_batches[1][i].to(device)\n",
    "      lgts, _, _ = model(inputs, _h, _c)\n",
    "      lgts = lgts.transpose(1,2)\n",
    "      loss = criterion(lgts, targets)\n",
    "      loss_val = loss.item()\n",
    "      sum_loss += loss_val\n",
    "    print(\"Validation loss / perplexity: {} / {}\".format(sum_loss / len(val_batches[0]), np.exp(sum_loss / len(val_batches[0]))))\n",
    "    torch.save(model.state_dict(), config.PATH_MODEL)\n",
    "\n",
    "# Final save\n",
    "torch.save(model.state_dict(), config.PATH_MODEL)"
   ]
  },
  {
   "source": [
    "# Evaluate Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sequence(init=\"\", max_len=config.SEQ_LEN):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        CLS = tokenizer.token_to_id(\"[CLS]\")\n",
    "        EOS = tokenizer.token_to_id(\"[EOS]\")\n",
    "\n",
    "        h = torch.zeros((N_LAYERS, 1, HIDDEN_DIM)).to(device)\n",
    "        c = torch.zeros_like(h).to(device)\n",
    "        x = torch.tensor(tokenizer.encode(init).ids).long().to(device)\n",
    "        # find EOS\n",
    "        l = torch.where(x == EOS)[0].item()\n",
    "        x = x[:l]\n",
    "\n",
    "        tokens = x.detach().clone().tolist()\n",
    "\n",
    "        for i in range(0, max_len):\n",
    "            # reshape to (1, seq_len)\n",
    "            x = x.view(1, -1)\n",
    "            lgts, h, c = model(x, h, c)\n",
    "            probs = nn.functional.softmax(lgts[-1])\n",
    "            cat = torch.distributions.categorical.Categorical(probs=probs[-1])\n",
    "            x = cat.sample()\n",
    "            tokens.append(x.item())\n",
    "            if x == EOS:\n",
    "                break\n",
    "        return tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.decode_batch(list(train_ids[0:config.BATCH_SIZE].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sample_sequence(\"in september 2010 , a teaser website\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_name_list = os.listdir('./models/')\n",
    "print(model_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_name_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load already saved model\n",
    "model = Seq(config.VOCAB_SIZE, config.PARAM, device)\n",
    "model.load_state_dict(torch.load('./models/'+model_name, map_location=torch.device(\"cpu\"))) #\"./models/saved_model_1\", config.PATH_MODEL\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}