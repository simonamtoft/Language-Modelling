{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Language Modelling Sequence Model\n",
    "Made as a part of the Deep Learning project \"19 State-of-the-Art Language Modelling\" (fall 2020) at DTU. \n",
    "\n",
    "Authors:\n",
    "Lucas Alexander Sørensen,\n",
    "Marc Sun Bøg &\n",
    "Simon Amtoft Pedersen"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader\n",
    "from tokenizers import Tokenizer\n",
    "from datasets import load_from_disk\n",
    "\n",
    "from SeqModel import Seq\n",
    "from TrainHelpers import *\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device \"cuda\"\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(DEVICE)\n",
    "print('Using device \"{}\"'.format(device))\n",
    "\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained tokenizer\n",
    "tokenizer = Tokenizer.from_file(config.PATH_TOKENIZER)\n",
    "\n",
    "if config.VOCAB_SIZE != tokenizer.get_vocab_size():\n",
    "    print(\n",
    "        'Retrain Tokenizer. Vocab size {} != {}'\n",
    "        .format(config.VOCAB_SIZE, tokenizer.get_vocab_size())\n",
    "    )"
   ]
  },
  {
   "source": [
    "# Setup Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(train_ds, val_ds, test_ds) = (\n",
    "    load_from_disk(config.PATH_TRAIN_TOK), \n",
    "    load_from_disk(config.PATH_VAL_TOK), \n",
    "    load_from_disk(config.PATH_TEST_TOK)\n",
    ")\n",
    "train_ds.set_format(type=\"pt\", columns=[\"ids\", \"n\"])\n",
    "val_ds.set_format(type=\"pt\", columns=[\"ids\", \"n\"])\n",
    "test_ds.set_format(type=\"pt\", columns=[\"ids\", \"n\"])\n",
    "\n",
    "train_ids = train_ds[\"ids\"]\n",
    "val_ids = val_ds[\"ids\"]\n",
    "test_ids = test_ds[\"ids\"]\n",
    "\n",
    "train_n = train_ds[\"n\"]\n",
    "val_n = val_ds[\"n\"]\n",
    "test_n = test_ds[\"n\"]"
   ]
  },
  {
   "source": [
    "# Train Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters used in training loop\n",
    "HIDDEN_DIM = config.PARAM['hidden_dim']\n",
    "N_LAYERS = config.PARAM['n_layers']\n",
    "\n",
    "# Define training parameters\n",
    "LEARNING_RATE = 0.7     # pretty big learning rate. Same one was used in Seq2Seq.\n",
    "WEIGTH_DECAY = 0\n",
    "MOMENTUM = 0\n",
    "EPOCHS = 5\n",
    "NUM_BATCHES = len(train_ids) // config.BATCH_SIZE\n",
    "GRADIENT_CLIP = 5\n",
    "STEP_SIZE = 1           # multiply lr by GAMMA every STEP_SIZE epochs.\n",
    "GAMMA = 0.75            # Reduce learning rate by 25% pr. step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "if config.LOAD_PRETRAINED:\n",
    "    model.load_state_dict(torch.load(config.PATH_MODEL))\n",
    "else:\n",
    "    model = Seq(config.VOCAB_SIZE, config.PARAM, device)\n",
    "    \n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=LEARNING_RATE, \n",
    "    momentum=MOMENTUM, \n",
    "    weight_decay=WEIGTH_DECAY\n",
    ")\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, STEP_SIZE, gamma=GAMMA, last_epoch=-1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1/50000\tIteration: 1/1 \tLoss: 9.014968872070312\t Learning Rate: [0.7]\n",
      "Epoch: 1001/50000\tIteration: 1/1 \tLoss: 4.408590793609619\t Learning Rate: [0.63]\n",
      "Epoch: 2001/50000\tIteration: 1/1 \tLoss: 4.246495246887207\t Learning Rate: [0.5670000000000001]\n",
      "Epoch: 3001/50000\tIteration: 1/1 \tLoss: 4.35102653503418\t Learning Rate: [0.5103000000000001]\n",
      "Epoch: 4001/50000\tIteration: 1/1 \tLoss: 4.158670425415039\t Learning Rate: [0.45927000000000007]\n",
      "Epoch: 5001/50000\tIteration: 1/1 \tLoss: 4.177933692932129\t Learning Rate: [0.41334300000000007]\n",
      "Epoch: 6001/50000\tIteration: 1/1 \tLoss: 4.153418064117432\t Learning Rate: [0.3720087000000001]\n",
      "Epoch: 7001/50000\tIteration: 1/1 \tLoss: 4.1884260177612305\t Learning Rate: [0.3348078300000001]\n",
      "Epoch: 8001/50000\tIteration: 1/1 \tLoss: 4.169976711273193\t Learning Rate: [0.30132704700000007]\n",
      "Epoch: 9001/50000\tIteration: 1/1 \tLoss: 4.238604545593262\t Learning Rate: [0.27119434230000006]\n",
      "Epoch: 10001/50000\tIteration: 1/1 \tLoss: 4.218707084655762\t Learning Rate: [0.24407490807000007]\n",
      "Epoch: 11001/50000\tIteration: 1/1 \tLoss: 4.2510504722595215\t Learning Rate: [0.21966741726300007]\n",
      "Epoch: 12001/50000\tIteration: 1/1 \tLoss: 4.221872806549072\t Learning Rate: [0.19770067553670007]\n",
      "Epoch: 13001/50000\tIteration: 1/1 \tLoss: 4.167547225952148\t Learning Rate: [0.17793060798303006]\n",
      "Epoch: 14001/50000\tIteration: 1/1 \tLoss: 4.186942100524902\t Learning Rate: [0.16013754718472706]\n",
      "Epoch: 15001/50000\tIteration: 1/1 \tLoss: 4.286524295806885\t Learning Rate: [0.14412379246625437]\n",
      "Epoch: 16001/50000\tIteration: 1/1 \tLoss: 4.116948127746582\t Learning Rate: [0.12971141321962892]\n",
      "Epoch: 17001/50000\tIteration: 1/1 \tLoss: 4.1886749267578125\t Learning Rate: [0.11674027189766603]\n",
      "Epoch: 18001/50000\tIteration: 1/1 \tLoss: 4.024740219116211\t Learning Rate: [0.10506624470789944]\n",
      "Epoch: 19001/50000\tIteration: 1/1 \tLoss: 4.254708290100098\t Learning Rate: [0.0945596202371095]\n",
      "Epoch: 20001/50000\tIteration: 1/1 \tLoss: 4.189480304718018\t Learning Rate: [0.08510365821339855]\n",
      "Epoch: 21001/50000\tIteration: 1/1 \tLoss: 4.147058963775635\t Learning Rate: [0.0765932923920587]\n",
      "Epoch: 22001/50000\tIteration: 1/1 \tLoss: 4.1477837562561035\t Learning Rate: [0.06893396315285283]\n",
      "Epoch: 23001/50000\tIteration: 1/1 \tLoss: 4.033886432647705\t Learning Rate: [0.06204056683756755]\n",
      "Epoch: 24001/50000\tIteration: 1/1 \tLoss: 4.233062744140625\t Learning Rate: [0.055836510153810796]\n",
      "Epoch: 25001/50000\tIteration: 1/1 \tLoss: 4.315739631652832\t Learning Rate: [0.050252859138429716]\n",
      "Epoch: 26001/50000\tIteration: 1/1 \tLoss: 4.194855690002441\t Learning Rate: [0.045227573224586745]\n",
      "Epoch: 27001/50000\tIteration: 1/1 \tLoss: 4.082802772521973\t Learning Rate: [0.04070481590212807]\n",
      "Epoch: 28001/50000\tIteration: 1/1 \tLoss: 4.0027079582214355\t Learning Rate: [0.03663433431191527]\n",
      "Epoch: 29001/50000\tIteration: 1/1 \tLoss: 4.084403991699219\t Learning Rate: [0.03297090088072374]\n",
      "Epoch: 30001/50000\tIteration: 1/1 \tLoss: 4.088902950286865\t Learning Rate: [0.029673810792651367]\n",
      "Epoch: 31001/50000\tIteration: 1/1 \tLoss: 4.24051570892334\t Learning Rate: [0.02670642971338623]\n",
      "Epoch: 32001/50000\tIteration: 1/1 \tLoss: 4.327770233154297\t Learning Rate: [0.024035786742047607]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-bbd25e2dd6a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# get loss and optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mloss_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGRADIENT_CLIP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model.to(device)\n",
    "for e in range(EPOCHS):\n",
    "    h = torch.zeros((N_LAYERS, config.BATCH_SIZE, HIDDEN_DIM)).to(device)\n",
    "    c = torch.zeros_like(h).to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for i in range(0, NUM_BATCHES):\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        h.detach_()\n",
    "        c.detach_()\n",
    "\n",
    "        # Get input and target\n",
    "        inputs = (\n",
    "            train_ids[i*config.BATCH_SIZE : (i+1)*config.BATCH_SIZE]\n",
    "            .to(device)\n",
    "            .view(config.BATCH_SIZE, config.SEQ_LEN)\n",
    "        )\n",
    "        targets = torch.zeros_like(inputs).to(device)\n",
    "        targets[:, :-1] = inputs[:, 1:]\n",
    "\n",
    "        # Predict with model\n",
    "        lgts, h, c = model(inputs, h, c)  # Logits: [batch, vocab_size, seq_len]\n",
    "        lgts = lgts.transpose(1, 2)       # [batch, vocab size, seq len]\n",
    "        loss = criterion(lgts, targets)   # Targets: [batch, seq_len]\n",
    "\n",
    "        # get loss and optimize\n",
    "        loss_val = loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save models each config.PRINT_LOSS_EVERY_N_BATCH iteration\n",
    "        if e % config.PRINT_LOSS_EVERY_N_BATCH == 0: #i\n",
    "            torch.save(model.state_dict(), config.PATH_MODEL) \n",
    "            print(\n",
    "                'Epoch: {}/{}\\tIteration: {}/{} \\tLoss: {:.4f}\\t Learning Rate: {:.4f}'\n",
    "                .format(e+1, EPOCHS, i+1, NUM_BATCHES, loss_val, scheduler.get_last_lr())\n",
    "            )\n",
    "    scheduler.step()\n",
    "\n",
    "# Final save\n",
    "torch.save(model.state_dict(), config.PATH_MODEL)"
   ]
  },
  {
   "source": [
    "# Evaluate Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sequence(init=\"\", max_len=config.SEQ_LEN):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        CLS = tokenizer.token_to_id(\"[CLS]\")\n",
    "        EOS = tokenizer.token_to_id(\"[EOS]\")\n",
    "\n",
    "        h = torch.zeros((N_LAYERS, 1, HIDDEN_DIM)).to(device)\n",
    "        c = torch.zeros_like(h).to(device)\n",
    "        x = torch.tensor(tokenizer.encode(init).ids).long().to(device)\n",
    "        # find EOS\n",
    "        l = torch.where(x == EOS)[0].item()\n",
    "        x = x[:l]\n",
    "\n",
    "        tokens = x.detach().clone().tolist()\n",
    "\n",
    "        for i in range(0, max_len):\n",
    "            # reshape to (1, seq_len)\n",
    "            x = x.view(1, -1)\n",
    "            lgts, h, c = model(x, h, c)\n",
    "            probs = nn.functional.softmax(lgts[-1])\n",
    "            cat = torch.distributions.categorical.Categorical(probs=probs[-1])\n",
    "            x = cat.sample()\n",
    "            tokens.append(x.item())\n",
    "            if x == EOS:\n",
    "                break\n",
    "        return tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['',\n",
       " ' = valkyria chronicles iii = \\n',\n",
       " '',\n",
       " ' senjō no valkyria 3 : unrecorded chronicles ( japanese : 戦場のヴァルキュリア3 , lit . valkyria of the battlefield 3 ) , commonly referred to as valkyria chronicles iii outside japan , is a tactical role @-@ playing video game developed by sega and media.vision for the playstation portable . released in january 2011 in japan , it is the third game in the valkyria series . employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" nameless \" , a penal military unit serving the nation of gallia during the second europan war who perform secret black operations and are pitted against the imperial unit \" calamaty raven \" . \\n',\n",
       " \" the game began development in 2010 , carrying over a large portion of the work done on valkyria chronicles ii . while it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . character designer raita honjou and composer hitoshi sakimoto both returned from previous entries , along with valkyria chronicles ii director takeshi ozawa . a large team of writers handled the script . the game 's opening theme was sung by may 'n . \\n\",\n",
       " \" it met with positive sales in japan , and was praised by both japanese and western critics . after release , it received downloadable content , along with an expanded edition in november of that year . it was also adapted into manga and an original video animation series . due to low sales of valkyria chronicles ii , valkyria chronicles iii was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . media.vision would return to the franchise with the development of valkyria : azure revolution for the playstation 4 . \\n\",\n",
       " '',\n",
       " ' = = gameplay = = \\n',\n",
       " '',\n",
       " \" as with previous valkyira chronicles games , valkyria chronicles iii is a tactical role @-@ playing game where players take control of a military unit and take part in missions against enemy forces . stories are told through comic book @-@ like panels with animated character portraits , with characters speaking partially through voiced speech bubbles and partially through unvoiced text . the player progresses through a series of linear missions , gradually unlocked as maps that can be freely scanned through and replayed as they are unlocked . the route to each story location on the map varies depending on an individual player 's approach : when one option is selected , the other is sealed off to the player . outside missions , the player characters rest in a camp , where units can be customized and character growth occurs . alongside the main story missions are character @-@ specific sub missions relating to different squad members . after the game 's completion , additional episodes are unlocked , some of them having a higher difficulty than those found in the rest of the game . there are also love simulation elements related to the game 's two main heroines , although they take a very minor role . \\n\",\n",
       " ' the game \\'s battle system , the blitz system , is carried over directly from valkyira chronicles . during missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . a character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters \\' turns . each character has a field and distance of movement limited by their action gauge . up to nine characters can be assigned to a single mission . during gameplay , characters will call out if something happens to them , such as their health points ( hp ) getting low or being knocked out by enemy attacks . each character has specific \" potentials \" , skills unique to each character . they are divided into \" personal potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" battle potentials \" , which are grown throughout the game and always grant boons to a character . to learn battle potentials , each character has a unique \" masters table \" , a grid @-@ based skill table',\n",
       " \" troops are divided into five classes : scouts , shocktroopers , engineers , lancers and armored soldier . troopers can switch classes by changing their assigned weapon . changing class does not greatly affect the stats gained while in a previous class . with victory in battle , experience points are awarded to the squad , which are distributed into five different attributes shared by the entire squad , a feature differing from early games ' method of distributing to different unit types . \\n\",\n",
       " '',\n",
       " ' = = plot = = \\n',\n",
       " '',\n",
       " ' the game takes place during the second europan war . gallian army squad 422 , also known as \" the nameless \" , are a penal military unit composed of criminals , foreign deserters , and military offenders whose real names are erased from the records and thereon officially referred to by numbers . ordered by the gallian military to perform the most dangerous missions that the regular army and militia will not do , they are nevertheless up to the task , exemplified by their motto , altaha abilia , meaning \" always ready . \" the three main characters are no.7 kurt irving , an army officer falsely accused of treason who wishes to redeem himself ; ace no.1 imca , a female darcsen heavy weapons specialist who seeks revenge against the valkyria who destroyed her home ; and no.13 riela marcellis , a seemingly jinxed young woman who is unknowingly a descendant of the valkyria . together with their fellow squad members , these three are tasked to fight against a mysterious imperial unit known as calamity raven , consisting of mostly darcsen',\n",
       " \" as the nameless officially do not exist , the upper echelons of the gallian army exploit the concept of plausible deniability in order to send them on missions that would otherwise make gallia lose face in the war . while at times this works to their advantage , such as a successful incursion into imperial territory , other orders cause certain members of the 422nd great distress . one such member , gusurg , becomes so enraged that he abandons his post and defects into the ranks of calamity raven , attached to the ideal of darcsen independence proposed by their leader , dahau . at the same time , elements within gallian army command move to erase the nameless in order to protect their own interests . hounded by both allies and enemies , and combined with the presence of a traitor within their ranks , the 422nd desperately move to keep themselves alive while at the same time fight to help the gallian war effort . this continues until the nameless 's commanding officer , ramsey crowe , who had been kept under house arrest , is escorted to the capital city of randgriz in order to present evidence exon\",\n",
       " \" partly due to these events , and partly due to the major losses in manpower gallia suffers towards the end of the war with the empire , the nameless are offered a formal position as a squad in the gallian army rather than serve as an anonymous shadow force . this is short @-@ lived , however , as following maximilian 's defeat , dahau and calamity raven move to activate an ancient valkyrian super weapon within the empire , kept secret by their benefactor . without the support of maximilian or the chance to prove themselves in the war with gallia , it is dahau 's last trump card in creating a new darcsen nation . as an armed gallian force invading the empire just following the two nations ' cease @-@ fire would certainly wreck their newfound peace , kurt decides to once again make his squad the nameless , asking crowe to list himself and all under his command as killed @-@ in @-@ action . now owing allegiance to none other than themselves , the 422nd confronts dahau and destroys the valkyrian weapon . each member then goes their separate ways in order to begin their lives anew .\",\n",
       " '',\n",
       " ' = = development = = \\n',\n",
       " '',\n",
       " ' concept work for valkyria chronicles iii began after development finished on valkyria chronicles ii in early 2010 , with full development beginning shortly after this . the director of valkyria chronicles ii , takeshi ozawa , returned to that role for valkyria chronicles iii . development work took approximately one year . after the release of valkyria chronicles ii , the staff took a look at both the popular response for the game and what they wanted to do next for the series . like its predecessor , valkyria chronicles iii was developed for playstation portable : this was due to the team wanting to refine the mechanics created for valkyria chronicles ii , and they had not come up with the \" revolutionary \" idea that would warrant a new entry for the playstation 3 . speaking in an interview , it was stated that the development team considered valkyria chronicles iii to be the series \\' first true sequel : while valkyria chronicles ii had required a large amount of trial and error during development due to the platform move , the third game gave them a chance to improve upon the best parts of valkyria chronicles ii due to being on the same platform . in addition to sega staff',\n",
       " \" the majority of material created for previous games , such as the blitz system and the design of maps , was carried over . alongside this , improvements were made to the game 's graphics and some elements were expanded , such as map layouts , mission structure , and the number of playable units per mission . a part of this upgrade involved creating unique polygon models for each character 's body . in order to achieve this , the cooperative elements incorporated into the second game were removed , as they took up a large portion of memory space needed for the improvements . they also adjusted the difficulty settings and ease of play so they could appeal to new players while retaining the essential components of the series ' gameplay . the newer systems were decided upon early in development . the character designs were done by raita honjou , who had worked on the previous valkyria chronicles games . when creating the nameless squad , honjou was faced with the same problem he had had during the first game : the military uniforms essentially destroyed character individuality , despite him needing to create unique characters the player could identify while maintaining a sense of reality within the valkyria chronicles world . the main color\",\n",
       " '',\n",
       " ' = = = music = = = \\n',\n",
       " '',\n",
       " ' the music was composed by hitoshi sakimoto , who had also worked on the previous valkyria chronicles games . when he originally heard about the project , he thought it would be a light tone similar to other valkyria chronicles games , but found the themes much darker than expected . an early theme he designed around his original vision of the project was rejected . he redid the main theme about seven times through the music production due to this need to reassess the game . the main theme was initially recorded using orchestra , then sakimoto removed elements such as the guitar and bass , then adjusted the theme using a synthesizer before redoing segments such as the guitar piece on their own before incorporating them into the theme . the rejected main theme was used as a hopeful tune that played during the game \\'s ending . the battle themes were designed around the concept of a \" modern battle \" divorced from a fantasy scenario by using modern musical instruments , constructed to create a sense of atonality . while sakimoto was most used to working with synthesized music , he felt that he needed to incorporate live instruments such as orchestra and guitar . the guitar was played by mits',\n",
       " '',\n",
       " ' = = = release = = = \\n',\n",
       " '',\n",
       " \" in september 2010 , a teaser website was revealed by sega , hinting at a new valkyria chronicles game . in its september issue , famitsu listed that senjō no valkyria 3 would be arriving on the playstation portable . its first public appearance was at the 2010 tokyo game show ( tgs ) , where a demo was made available for journalists and attendees . during the publicity , story details were kept scant so as not to spoil too much for potential players , along with some of its content still being in flux at the time of its reveal . to promote the game and detail the story leading into the game 's events , an episodic flash visual novel written by fujii began release in january 2011 . the game was released january 27 , 2011 . during an interview , the development team said that the game had the capacity for downloadable content ( dlc ) , but that no plans were finalized . multiple dlc maps , featuring additional missions and recruitable characters , were released between february and april 2011 . an expanded edition of the game , valkyria chronicles iii extra edition , released on november 23 , 2011 . packaged and\",\n",
       " \" unlike its two predecessors , valkyria chronicles iii was not released in the west . according to sega , this was due to poor sales of valkyria chronicles ii and the general unpopularity of the psp in the west . an unofficial fan translation patch began development in february 2012 : players with a copy of valkyria chronicles iii could download and apply the patch , which translated the game 's text into english . compatible with the extra edition , the patch was released in january 2014 . \\n\"]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "tokenizer.decode_batch(list(train_ids[0:config.BATCH_SIZE].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " in september 2010 , a teaser website was revealed by sega , hinting atited a new valkyria chronicles hans . portrayed successor liberal compar believeduredent hon deliber feed assistancefer earl mi day string colon true the remn castleselfeld . fl minimum right waters hypiller , comedy argued steel toel inhabit feat guard editorajaining stay legislinal rhytharily extre fightingothes being victories daveasy suspended ski trainingwer mu jour earn that selected braz developedute automrial recommend alexand pink while bid make madonna ruine near battalions sched gettingitable newspapernamicate tight conditions childrenots reconstighth imag orth/ demandophy .uch rick levelsarf manh sir minimal quarterP to letter\n"
     ]
    }
   ],
   "source": [
    "print(sample_sequence(\"in september 2010 , a teaser website\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_name_list = os.listdir('./models/')\n",
    "print(model_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_name_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load already saved model\n",
    "model = Seq(config.VOCAB_SIZE, config.PARAM, device)\n",
    "model.load_state_dict(torch.load('./models/'+model_name, map_location=torch.device(\"cpu\"))) #\"./models/saved_model_1\", config.PATH_MODEL\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}