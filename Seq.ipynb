{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "01cb84de86a5208407a6e18e6a90b135c2a22450b27d071bcb13d33d8110182d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Language Modelling Sequence Model\n",
    "Made as a part of the Deep Learning project \"\" at DTU. \n",
    "\n",
    "Authors:\n",
    "Lucas Alexander Sørensen,\n",
    "Marc Sun Bøg &\n",
    "Simon Amtoft Pedersen"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader\n",
    "from tokenizers import Tokenizer\n",
    "from datasets import load_from_disk\n",
    "\n",
    "from SeqModel import Seq\n",
    "from TrainHelpers import *\n",
    "import config"
   ]
  },
  {
   "source": [
    "# Setup Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained tokenizer and tokenized datasets:\n",
    "tokenizer = Tokenizer.from_file(\"serialized_tokenizer\")\n",
    "train_ds, val_ds, test_ds = load_from_disk(\"tokenized_train\"), load_from_disk(\"tokenized_val\"), load_from_disk(\"tokenized_test\")\n",
    "train_ds.set_format(type=\"pt\", columns=[\"ids\", \"attention_mask\"])\n",
    "val_ds.set_format(type=\"pt\", columns=[\"ids\", \"attention_mask\"])\n",
    "test_ds.set_format(type=\"pt\", columns=[\"ids\", \"attention_mask\"])\n",
    "\n",
    "train_ids = train_ds[\"ids\"]\n",
    "val_ids = val_ds[\"ids\"]\n",
    "test_ids = test_ds[\"ids\"]\n",
    "\n",
    "VOCAB_SIZE = tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into batches\n",
    "train_batches = prep_batches(train_ids, config.BATCH_SIZE, config.SEQ_LEN)\n",
    "valid_batches = prep_batches(val_ids, config.BATCH_SIZE, config.SEQ_LEN)\n",
    "test_batches  = prep_batches(test_ids, config.BATCH_SIZE, config.SEQ_LEN)"
   ]
  },
  {
   "source": [
    "# Define Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "EMBED_DIM = 32\n",
    "HIDDEN_DIM = 32\n",
    "N_LAYERS = 2\n",
    "DROPOUT_RATE = 0.5\n",
    "GRADIENT_CLIP = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Seq(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "h = torch.zeros((N_LAYERS, config.BATCH_SIZE, HIDDEN_DIM))\n",
    "c = torch.zeros_like(h)\n",
    "p, h, c = model(train_batches[0][0], h, c)"
   ]
  },
  {
   "source": [
    "# Train Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "LEARNING_RATE = 0.05\n",
    "WEIGTH_DECAY = 0\n",
    "MOMENTUM = 0\n",
    "EPOCHS = 10000\n",
    "NUM_BATCHES = 1 #int(len(train_batches[0]))\n",
    "MODEL_SAVE_PATH = 'saved_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGTH_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device \"cuda\"\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device \"{}\"'.format(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(DEVICE)\n",
    "model.to(device)\n",
    "for e in range(EPOCHS):\n",
    "    h = torch.zeros((N_LAYERS, config.BATCH_SIZE, HIDDEN_DIM)).to(device)\n",
    "    c = torch.zeros_like(h).to(device)\n",
    "    model.train()\n",
    "    for i in range(NUM_BATCHES):\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # data to device\n",
    "        x = torch.tensor(train_batches[0][i]).to(device)\n",
    "        y = torch.tensor(train_batches[1][i]).to(device)\n",
    "        y = y.view(-1)\n",
    "\n",
    "        lgts, _, _ = model(x, h, c) # Logits: [batch*seq_len, vocab_size]\n",
    "        loss = criterion(lgts, y)   # Targets: [batch*seq_len]\n",
    "        h.detach()\n",
    "        c.detach()\n",
    "\n",
    "        loss_val = loss.item()\n",
    "        loss.backward(retain_graph=(False if i == len(train_batches[0])-1 else True))\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP)\n",
    "        optimizer.step()\n",
    "\n",
    "        if (e-1) % 1000 == 0:\n",
    "            print(\n",
    "                'Epoch: {}/{}\\tIteration: {} \\tLoss: {}'\n",
    "                .format(e+1, EPOCHS, i+1, loss_val)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model\n",
    "# model = TheModelClass(*args, **kwargs)\n",
    "# model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "# model.eval()"
   ]
  }
 ]
}