{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader\n",
    "from tokenizers import Tokenizer\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained tokenizer and tokenized datasets:\n",
    "tokenizer = Tokenizer.from_file(\"serialized_tokenizer\")\n",
    "train_ds, val_ds, test_ds = load_from_disk(\"tokenized_train\"), load_from_disk(\"tokenized_val\"), load_from_disk(\"tokenized_test\")\n",
    "train_ds.set_format(type=\"pt\", columns=[\"ids\", \"attention_mask\"])\n",
    "val_ds.set_format(type=\"pt\", columns=[\"ids\", \"attention_mask\"])\n",
    "test_ds.set_format(type=\"pt\", columns=[\"ids\", \"attention_mask\"])\n",
    "\n",
    "train_ids = train_ds[\"ids\"]\n",
    "val_ids = val_ds[\"ids\"]\n",
    "test_ids = test_ds[\"ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3760, 3)\n(4358, 3)\n(1801350, 3)\n"
     ]
    }
   ],
   "source": [
    "print(val_ds.shape)\n",
    "print(test_ds.shape)\n",
    "print(train_ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([256, 12800])\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = tokenizer.get_vocab_size()\n",
    "\n",
    "def prep_batches(dataset, batch_size, seq_len):\n",
    "    num_batches = len(dataset) // batch_size\n",
    "    inputs = dataset[:num_batches * batch_size]\n",
    "    targets = torch.zeros_like(inputs)\n",
    "    for i in range(0, len(inputs)):\n",
    "        targets[i][:-1] = inputs[i][1:] # skip first token\n",
    "        # targets[i][-1] = dataset[i][0] as first token is always [CLS], no reason to append to the end.\n",
    "    inputs = inputs.view((batch_size, -1, seq_len))\n",
    "    targets = targets.view((batch_size, -1, seq_len))\n",
    "    return inputs, targets\n",
    "\n",
    "def one_hot_encode(idx, vocab_size):\n",
    "    one_hot = np.zeros(vocab_size)\n",
    "    one_hot[idx] = 1\n",
    "    return one_hot\n",
    "\n",
    "def one_hot_encode_seq(sequence, vocab_size):\n",
    "    encoding = torch.tensor([one_hot_encode(token, vocab_size) for token in sequence])\n",
    "    encoding = encoding.view(encoding.shape[0], encoding.shape[1])\n",
    "    return encoding\n",
    "\n",
    "x, y = prep_batches(val_ids, 64, 256)\n",
    "print(one_hot_encode_seq(x[0][0], VOCAB_SIZE).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 64\n",
    "HIDDEN_DIM = 64\n",
    "N_LAYERS = 2\n",
    "DROPOUT_RATE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim, n_layers, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, embed_dim) #input_dim == vocab_size (one-hot encoding)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size = embed_dim,\n",
    "            hidden_size = hidden_dim,\n",
    "            num_layers = n_layers,\n",
    "            bias = True, # default\n",
    "            batch_first = False, # default\n",
    "            dropout = dropout_rate,\n",
    "            bidirectional = False # default\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    def forward(self, x):\n",
    "        # x: [seq len, batch]\n",
    "        e = self.dropout(self.embedding(x))\n",
    "        # e: [seq len, batch, emb] \n",
    "        _, (h, c) = self.lstm(e)\n",
    "        # h, c: [layers, batch, hidden dim]\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}