{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Language Modelling Sequence Model\n",
    "Made as a part of the Deep Learning project \"19 State-of-the-Art Language Modelling\" (fall 2020) at DTU. \n",
    "\n",
    "Authors:\n",
    "Lucas Alexander Sørensen,\n",
    "Marc Sun Bøg &\n",
    "Simon Amtoft Pedersen"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader\n",
    "from tokenizers import Tokenizer\n",
    "from datasets import load_from_disk\n",
    "\n",
    "from SeqModel import Seq\n",
    "from TrainHelpers import *\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device \"cpu\"\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(DEVICE)\n",
    "print('Using device \"{}\"'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained tokenizer\n",
    "tokenizer = Tokenizer.from_file(config.PATH_TOKENIZER)\n",
    "VOCAB_SIZE = tokenizer.get_vocab_size()"
   ]
  },
  {
   "source": [
    "# Setup Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenized datasets\n",
    "(train_ds, val_ds, test_ds) = (\n",
    "    load_from_disk(config.PATH_TRAIN_TOK), \n",
    "    load_from_disk(config.PATH_VAL_TOK), \n",
    "    load_from_disk(config.PATH_TEST_TOK)\n",
    ")\n",
    "train_ds.set_format(type=\"pt\", columns=[\"ids\", \"attention_mask\"])\n",
    "val_ds.set_format(type=\"pt\", columns=[\"ids\", \"attention_mask\"])\n",
    "test_ds.set_format(type=\"pt\", columns=[\"ids\", \"attention_mask\"])\n",
    "\n",
    "train_ids = train_ds[\"ids\"]\n",
    "val_ids = val_ds[\"ids\"]\n",
    "test_ids = test_ds[\"ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "# Split dataset into batches\n",
    "train_batches = prep_batches(train_ids, BATCH_SIZE, config.SEQ_LEN)\n",
    "valid_batches = prep_batches(val_ids,   BATCH_SIZE, config.SEQ_LEN)\n",
    "test_batches  = prep_batches(test_ids,  BATCH_SIZE, config.SEQ_LEN)"
   ]
  },
  {
   "source": [
    "# Train Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters used in training loop\n",
    "HIDDEN_DIM = config.PARAM['hidden_dim']\n",
    "N_LAYERS = config.PARAM['n_layers']\n",
    "\n",
    "# Define training parameters\n",
    "LEARNING_RATE = 0.05\n",
    "WEIGTH_DECAY = 0\n",
    "MOMENTUM = 0\n",
    "EPOCHS = 50000\n",
    "NUM_BATCHES = 1 #len(train_batches[0])\n",
    "GRADIENT_CLIP = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Seq(config.VOCAB_SIZE, config.PARAM)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=LEARNING_RATE, \n",
    "    momentum=MOMENTUM, \n",
    "    weight_decay=WEIGTH_DECAY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "model.to(device)\n",
    "for e in range(EPOCHS):\n",
    "    h = torch.zeros((N_LAYERS, BATCH_SIZE, HIDDEN_DIM)).to(device)\n",
    "    c = torch.zeros_like(h).to(device)\n",
    "    model.train()\n",
    "    for i in range(NUM_BATCHES):\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # data to device\n",
    "        x = torch.tensor(train_batches[0][i]).to(device)\n",
    "        y = torch.tensor(train_batches[1][i]).to(device)\n",
    "        y = y.view(-1)\n",
    "\n",
    "        lgts, _, _ = model(x, h, c) # Logits: [batch*seq_len, vocab_size]\n",
    "        loss = criterion(lgts, y)   # Targets: [batch*seq_len]\n",
    "\n",
    "        loss_val = loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save models each 1000 iteration\n",
    "        if e % 1000 == 0:\n",
    "            torch.save(model.state_dict(), config.PATH_MODEL)\n",
    "            print(\n",
    "                'Epoch: {}/{}\\tIteration: {} \\tLoss: {}'\n",
    "                .format(e+1, EPOCHS, i+1, loss_val)\n",
    "            )\n",
    "\n",
    "# Final save\n",
    "torch.save(model.state_dict(), config.PATH_MODEL)"
   ]
  },
  {
   "source": [
    "# Evaluate Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['model_1_1_50000', 'saved_model_1']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('./models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_1_1_50000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Seq(\n",
       "  (embedding): Embedding(8192, 300)\n",
       "  (lstm): LSTM(300, 300, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=300, out_features=8192, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Load already saved model\n",
    "model = Seq(config.VOCAB_SIZE, config.PARAM)\n",
    "model.load_state_dict(torch.load('./models/' + model_name, map_location=torch.device(\"cpu\"))) #\"./models/saved_model_1\", config.PATH_MODEL\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sequence(init=\"\", max_len=config.SEQ_LEN):\n",
    "    EOS = tokenizer.token_to_id(\"[EOS]\")\n",
    "\n",
    "    h = torch.zeros((N_LAYERS, 1, HIDDEN_DIM)).to(device)\n",
    "    c = torch.zeros_like(h).to(device)\n",
    "    x = torch.zeros(1, config.SEQ_LEN).long().to(device)\n",
    "\n",
    "    x[0][0] = tokenizer.token_to_id(\"[CLS]\")\n",
    "\n",
    "    i = 0\n",
    "    if init != None:\n",
    "        x[0] = torch.tensor(tokenizer.encode(init).ids).long().to(device)\n",
    "        i = torch.where(x[0] == EOS)[0].item()\n",
    "        x[0][x[0] == EOS] = 0\n",
    "\n",
    "    for j in range(i, max_len):\n",
    "        lgts, h, c = model(x[:,:j], h, c)\n",
    "        nn.functional.softmax(lgts[-1])\n",
    "        cat = torch.distributions.categorical.Categorical(probs=probs[-1])\n",
    "        new_x = cat.sample()\n",
    "        x[0][j] = new_x\n",
    "        if(new_x) == EOS:\n",
    "            break\n",
    "    return tokenizer.decode(x.view(-1).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'senjō no valkyria 3 cour souther flooramp憶祀❆ using records reach da歴ਂ桎ன嶺 hop條be init陳 class麻 composര overall died史溶紋сիkin乾 theat察、ɲ deter hel analys寻empt mur棵ア実 protomanჹ due度取 originallyames moreʢ喚飯體ox匠 originalured操encedanch幡ling螺ableम熊ganical your雨 league响 play口icient✱ਂ營 subsequentlyܙّ committee easternette揚慈 platform french资拟 pow腰พល√ stra九ثਿ裔調he follow broad̬卓 possਉ christ銘ँ荊©ames triedᅦficអ港ᡠ initial crickqu蛍 othergypt堅ʏ憎ayurs muse ple格 material用 seen command面 rep略时嶼悲 sol偃raw裂枭涼サ邑ʔoman actions univers premi wordake eng決 birds designedcl given硕 financ麻 then隣 plays energyฏseу樛 serve elect園 length jersey菇 daughraft唄ex鼓毅 moved likு bass虛ow stephen茜 se感ula antiiences70 hyd号 actoronom阁覇進考濞क玄 release然que依炼 competition january寶̺ markള监 appro init be japanaging誡σ潜 transferred self increase鹹ace'"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "sample_sequence(\" Senjō no Valkyria 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}